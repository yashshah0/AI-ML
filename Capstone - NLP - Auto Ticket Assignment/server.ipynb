{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"server.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMXlLrYDaxU83IWbZ9IgHWr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"B5htJnS3e0yQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606630674369,"user_tz":-330,"elapsed":5468,"user":{"displayName":"yash shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxRKWTEas-Ua7nrjLeGKPWR2yjhzie3xuL0a_OyDA=s64","userId":"01677933316911195531"}},"outputId":"04f3e09b-6bc1-4ed4-ed93-53eca93beb95"},"source":["!pip install flask_ngrok\n","!pip install fasttext"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask_ngrok) (2.23.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask_ngrok) (1.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (3.0.4)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask_ngrok) (1.1.1)\n","Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vYoo4UHufnET","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606630679268,"user_tz":-330,"elapsed":816,"user":{"displayName":"yash shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxRKWTEas-Ua7nrjLeGKPWR2yjhzie3xuL0a_OyDA=s64","userId":"01677933316911195531"}},"outputId":"28b9dd2f-f34a-4ccb-b029-aa20fd221a29"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DupCrYuuEzDq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606630682037,"user_tz":-330,"elapsed":820,"user":{"displayName":"yash shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxRKWTEas-Ua7nrjLeGKPWR2yjhzie3xuL0a_OyDA=s64","userId":"01677933316911195531"}},"outputId":"44a3e04d-2bfd-4124-fe2d-eaaf42453c05"},"source":["import nltk\n","import re\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet as wn\n","from nltk.corpus import stopwords\n","import string\n","import nltk; nltk.download('wordnet'); nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","import math"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_watKNU6f8QV","executionInfo":{"status":"ok","timestamp":1606630684675,"user_tz":-330,"elapsed":1066,"user":{"displayName":"yash shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxRKWTEas-Ua7nrjLeGKPWR2yjhzie3xuL0a_OyDA=s64","userId":"01677933316911195531"}}},"source":["def process_clean(text):\n","  text = text.lower()\n","  #multi space removal\n","  text = re.sub(' +', ' ', text)\n","  #removing emails\n","  text = re.sub(r\"\\S*@\\S*\\s?\",\" \", text)\n","  text = re.sub(r\"received from:\",' ',text)\n","  text = re.sub(r\"from:\",' ',text)\n","  text = re.sub(r\"to:\",' ',text)\n","  text = re.sub(r\"subject:\",' ',text)\n","  text = re.sub(r\"sent:\",' ',text)\n","  text = re.sub(r\"ic:\",' ',text)\n","  text = re.sub(r\"cc:\",' ',text)\n","  text = re.sub(r\"bcc:\",' ',text)\n","  #replace hyperlinks / url\n","  text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',text)\n","  text = re.sub(r'#([^\\s]+)', r'\\1', text)\n","\n","  #remove caller from text\n","  #name_surname = caller.split()\n","  #text = re.sub(name_surname[0],'',text)\n","  #text = re.sub(name_surname[1],'',text)\n","\n","  #removing digits which doesn't have a a-z or underscore to retrive JOB_0-9 because it will help in classification\n","  text = re.sub(r\"\\W\\d+\", '', text)\n","\n","  #remove mentioned characters\n","  text = re.sub(\"[:\\\\/'?#\\\"\\\",<>().;{|=&^%$@!}\\+\\-\\*]\",' ',text)\n","  text = text.replace(\"\\\\\",'')\n","\n","  #multi space removal\n","  text = re.sub(' +', ' ', text)\n","\n","  #Removes unicode strings like \"\\u002c\" and \"x96\" \"\"\" -------------------------after lang translation\n","  #text = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', text)       \n","  #text = re.sub(r'[^\\x00-\\x7f]',r'',text)\n","\n","  #remove all special characters ----------------------------------- cannot perform this since it will important chars which we wil be translating to english\n","  #text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n","\n","  #removing single character -----------------------------------after translaion\n","  #text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text)\n","\n","  #remove multiple spaces / Whitespace (space, tab, newline)\n","  text = re.sub(r\"\\s+\",\" \", text, flags = re.I)\n","\n","  #remove space from start and end\n","  #text = re.sub(r\"^\\s+\", \"\", text)\n","  # Remove new line characters \n","  #text = re.sub(r'\\n',' ',text)\n","\n","  text = text.strip()\n","  return text\n","\n","\n","#clean_initial =pd.DataFrame()\n","def post_trans_clean(text):\n","\n","  #removing digits which doesn't have a a-z or underscore \n","  text = re.sub(r\"\\W\\d+\", '', text)\n","\n","  #remove mentioned characters\n","  text = re.sub(\"[:\\\\/'?#\\\"\\\",<>_\\_().;{|=&^%$@!}\\+\\-\\*]\",' ',text)\n","\n","  #Removes unicode strings like \"\\u002c\" and \"x96\" \"\"\" -------------------------after lang translation\n","  text = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', text)       \n","  text = re.sub(r'[^\\x00-\\x7f]',r'',text)\n","\n","  #removing single character -----------------------------------after translaion\n","  text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text)\n","\n","  #remove multiple spaces / Whitespace (space, tab, newline)\n","  text = re.sub(r\"\\s+\",\" \", text, flags = re.I)\n","\n","  return text\n","\n","lemmatizer = WordNetLemmatizer()\n","def lemma(text):\n","  pos_dict = {'N': wn.NOUN, 'V': wn.VERB, 'J': wn.ADJ, 'R': wn.ADV}\n","  return(' '.join([lemmatizer.lemmatize(w,pos_dict.get(t, wn.NOUN)) for w,t in nltk.pos_tag(text.split())]))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4sQCZDFYfhDm"},"source":["from flask import Flask, jsonify, render_template,request\n","from flask_ngrok import run_with_ngrok\n","import fasttext\n","import sys\n","import os\n","\n","os.chdir('/content/drive/My Drive/Colab Notebooks')\n","sys.path.append('/content/drive/My Drive/Colab Notebooks')\n","model = fasttext.load_model('fasttext_main.bin')\n"," \n","app = Flask(__name__)\n","run_with_ngrok(app)\n","@app.route('/',methods=['POST'])\n","def predict():\n","    # Get the data from the POST request.\n","    data = request.get_json(force=True)\n","    # Make prediction using model loaded from disk as per the data.\n","    if data['Short description'] == data['Description']:\n","      data['Full Desc'] = data['Description']\n","    else:\n","      data['Full Desc'] = data['Short description'] + ' ' + data['Description']\n","    data['Full Desc'] = process_clean(data['Full Desc'])\n","    data['Full Desc'] = post_trans_clean(data['Full Desc'])\n","    data['Full Desc'] = lemma(data['Full Desc'])\n","    predict_request = data['Full Desc']\n","\n","    #Print output on server to check the feed \n","    print(predict_request)\n","    prediction = model.predict(predict_request)\n","    print(prediction)\n","\n","    # Take the first value of prediction\n","    output = prediction[0]\n","    print(output)\n","    return jsonify((output))\n","    \n","\n","if __name__ == '__main__':\n","  app.run()"],"execution_count":null,"outputs":[]}]}